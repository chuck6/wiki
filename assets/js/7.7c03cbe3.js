(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{522:function(a,t,_){a.exports=_.p+"assets/img/es_readmk_76.3b11249a.png"},523:function(a,t,_){a.exports=_.p+"assets/img/es_readmk_77.c286016f.png"},524:function(a,t,_){a.exports=_.p+"assets/img/es_readmk_78.b8212fe8.png"},525:function(a,t,_){a.exports=_.p+"assets/img/es_readmk_79.d43bcc38.png"},769:function(a,t,_){"use strict";_.r(t);var v=_(20),e=Object(v.a)({},(function(){var a=this,t=a.$createElement,v=a._self._c||t;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("p",[v("strong",[a._v("ELK中架构知识点整理")])]),a._v(" "),v("h1",{attrs:{id:"es集群节点部署方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#es集群节点部署方式"}},[a._v("#")]),a._v(" ES集群节点部署方式")]),a._v(" "),v("p",[a._v("这里说的集群部署方式的整理，主要针对的是对于node(节点)的规划，在ES中有很多种节点角色。")]),a._v(" "),v("h2",{attrs:{id:"为什么要进行节点规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么要进行节点规划"}},[a._v("#")]),a._v(" 为什么要进行节点规划")]),a._v(" "),v("p",[a._v("ES中有很多种节点的角色，承担不同的角色任务。节点角色规划的好坏，涉及到如何ES中master节点的高可用，data节点的水平扩展，读写分离等。")]),a._v(" "),v("h2",{attrs:{id:"节点和机器是什么关系"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#节点和机器是什么关系"}},[a._v("#")]),a._v(" 节点和机器是什么关系")]),a._v(" "),v("p",[a._v("节点是一个ES的实例。")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("本质上就是一个JAVA进程")])]),a._v(" "),v("li",[v("p",[a._v("一台机器上可以运行多个ES进程，但是生产环境一般建议一台机器上只运行一个es的实例。")])]),a._v(" "),v("li",[v("p",[a._v("单节点ES的JVM内存尽量不超过32G")])]),a._v(" "),v("li",[v("p",[a._v("单节点存储数据量尽量不要超过5TB")])]),a._v(" "),v("li",[v("p",[a._v("高并发搜索场景推荐单节点配置16C/64G/2TB SSD")])]),a._v(" "),v("li",[v("p",[a._v("ES集群节点数不要超过300.")])])]),a._v(" "),v("h2",{attrs:{id:"节点类型有哪些"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#节点类型有哪些"}},[a._v("#")]),a._v(" 节点类型有哪些")]),a._v(" "),v("p",[a._v("需要注意的是节点和角色是两个概念，一个节点可以承担多种角色，也可以一个节点单一角色。")]),a._v(" "),v("p",[a._v("ES中有多种节点角色，有Master eligible、data、Ingest、Corrdinating、Machine learning等。")]),a._v(" "),v("p",[v("strong",[a._v("master node")]),a._v("：处理创建，删除索引等请求 / 决定分片被分配到哪个节点 / 负责索引的创建与删除；集群状态，维护了一个集群中必要的信息（所有的节点信息、所有的索引和其相关的Mapping与Setting信息、分片的路由信息）")]),a._v(" "),v("p",[v("strong",[a._v("master eligible")]),a._v("：一个集群，支持配置多个Master Eligible节点。这些节点可以在必要的时候(如Master节点出现故障，网络故障时)参与选主流程，成为Master节点。")]),a._v(" "),v("p",[v("strong",[a._v("data node")]),a._v("：保存包含索引文档的分片数据，执行CRUD、搜索、聚合相关的操作。属于：内存、CPU、IO密集型，对硬件资源要求高。")]),a._v(" "),v("p",[v("strong",[a._v("Coordinating Node")]),a._v("：搜索请求在两个阶段中执行（query 和 fetch），这两个阶段由接收客户端请求的节点 - 协调节点协调。在请求阶段，协调节点将请求转发到保存数据的数据节点。 每个数据节点在本地执行请求并将其结果返回给协调节点。在收集fetch阶段，协调节点将每个数据节点的结果汇集为单个全局结果集。")]),a._v(" "),v("p",[v("strong",[a._v("ingress node")]),a._v("：ingest 节点可以看作是数据前置处理转换的节点，支持 pipeline管道 设置，可以使用 ingest 对数据进行过滤、转换等操作，类似于 logstash 中 filter 的作用，功能相当强大。可以把Ingest节点的功能抽象为："),v("strong",[a._v("大数据处理环节的“ETL”")]),a._v("——抽取、转换、加载。")]),a._v(" "),v("p",[v("strong",[a._v("hot&warm node")]),a._v("：不同硬件配置的Data Node,用来实现Hot&Warm架构，降低集群部署的成本。")]),a._v(" "),v("p",[v("strong",[a._v("Machine Learing Node")]),a._v("：负责跑机器学习的Job，用来做异常检测。")]),a._v(" "),v("blockquote",[v("p",[a._v("在开发测试环境中，一个节点可以承担多种角色；")]),a._v(" "),v("p",[a._v("在生产环境中，根据数据量、写入和查询的吞吐量，来选择合适的部署方式。建议设置单一角色的节点(dedicated node)")])]),a._v(" "),v("h2",{attrs:{id:"节点角色如何定义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#节点角色如何定义"}},[a._v("#")]),a._v(" 节点角色如何定义")]),a._v(" "),v("p",[a._v("一个节点在默认情况下会同时扮演：master eligible，data node和ingress node。")]),a._v(" "),v("h3",{attrs:{id:"配置参数介绍"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#配置参数介绍"}},[a._v("#")]),a._v(" 配置参数介绍")]),a._v(" "),v("table",[v("thead",[v("tr",[v("th",[a._v("节点类型")]),a._v(" "),v("th",[a._v("配置参数")]),a._v(" "),v("th",[a._v("默认值")])])]),a._v(" "),v("tbody",[v("tr",[v("td",[a._v("master eligible")]),a._v(" "),v("td",[a._v("node.master")]),a._v(" "),v("td",[a._v("true")])]),a._v(" "),v("tr",[v("td",[a._v("data")]),a._v(" "),v("td",[a._v("node.data")]),a._v(" "),v("td",[a._v("true")])]),a._v(" "),v("tr",[v("td",[a._v("ingest")]),a._v(" "),v("td",[a._v("node.ingest")]),a._v(" "),v("td",[a._v("true")])]),a._v(" "),v("tr",[v("td",[a._v("coordinating only")]),a._v(" "),v("td",[a._v("无")]),a._v(" "),v("td",[a._v("设置上面三个参数全部是false")])]),a._v(" "),v("tr",[v("td",[a._v("machine learning")]),a._v(" "),v("td",[a._v("node.xml")]),a._v(" "),v("td",[a._v("true (需要enable x-pack)")])])])]),a._v(" "),v("h3",{attrs:{id:"单一角色节点配置"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#单一角色节点配置"}},[a._v("#")]),a._v(" 单一角色节点配置")]),a._v(" "),v("p",[a._v("单一的master节点：")]),a._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[a._v("node.master: true\nnode.ingest: false\nnode.data: false\n")])]),a._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[a._v("1")]),v("br"),v("span",{staticClass:"line-number"},[a._v("2")]),v("br"),v("span",{staticClass:"line-number"},[a._v("3")]),v("br")])]),v("p",[a._v("单一的data节点：")]),a._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[a._v("node.master: false\nnode.ingest: false\nndoe.data: true\n")])]),a._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[a._v("1")]),v("br"),v("span",{staticClass:"line-number"},[a._v("2")]),v("br"),v("span",{staticClass:"line-number"},[a._v("3")]),v("br")])]),v("p",[a._v("单一的ingest节点：")]),a._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[a._v("node.master: false\nnode.ingest: true\nnode.data: false\n")])]),a._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[a._v("1")]),v("br"),v("span",{staticClass:"line-number"},[a._v("2")]),v("br"),v("span",{staticClass:"line-number"},[a._v("3")]),v("br")])]),v("p",[a._v("单一的coordinate节点:")]),a._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[a._v("node.master: false\nnode.ingest: false\nnode.data: false\n")])]),a._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[a._v("1")]),v("br"),v("span",{staticClass:"line-number"},[a._v("2")]),v("br"),v("span",{staticClass:"line-number"},[a._v("3")]),v("br")])]),v("h3",{attrs:{id:"单一角色好处"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#单一角色好处"}},[a._v("#")]),a._v(" 单一角色好处")]),a._v(" "),v("p",[a._v("Dedicated master eligible nodes(或者dedicate master node)：")]),a._v(" "),v("ul",[v("li",[a._v("负责集群状态(cluter state)的管理")]),a._v(" "),v("li",[a._v("使用低配置的CPU，RAM和磁盘")]),a._v(" "),v("li",[a._v("在生产环境中配置3台；一个集群中只有1台活跃主节点(用于分片管理，索引创建，集群管理等操作)。高可用，避免脑裂。")]),a._v(" "),v("li",[a._v("生产上和数据节点合用不合适(数据节点占用内存较高)。")]),a._v(" "),v("li",[a._v("生产上和coordinate节点合用不合适(coordinate节点有时候可能会有开销很高的查询，导致OOM)")])]),a._v(" "),v("p",[a._v("Dedicated data nodes:")]),a._v(" "),v("ul",[v("li",[a._v("负责数据存储及处理客户端请求")]),a._v(" "),v("li",[a._v("使用高配置的CPU，RAM和磁盘")])]),a._v(" "),v("p",[a._v("Dedicate ingest nodes：")]),a._v(" "),v("ul",[v("li",[a._v("负责数据处理")]),a._v(" "),v("li",[a._v("使用高配置CPU，中等配置的RAM；低配置的磁盘。")])]),a._v(" "),v("p",[a._v("Dedicate Coordinating Only Node(client node)：")]),a._v(" "),v("ul",[v("li",[a._v("中高等配置CPU；中高等RAM；低配置的磁盘。")]),a._v(" "),v("li",[a._v("生产环境中，建议为一些大的集群配置coordinating only nodes。")]),a._v(" "),v("li",[a._v("可以扮演load balancers的角色。降低master和data nodes的负载。")]),a._v(" "),v("li",[a._v("负载搜索结果的gather / reduce")]),a._v(" "),v("li",[a._v("有时候无法预知客户端会发送怎么样的请求，例如有可能会有大量占用内存的聚合操作，一个深度聚合可能引发OOM。")])]),a._v(" "),v("h2",{attrs:{id:"数据节点水平扩展"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据节点水平扩展"}},[a._v("#")]),a._v(" 数据节点水平扩展")]),a._v(" "),v("p",[a._v("当数据节点的磁盘容量无法满足的时候，可以增加数据节点；磁盘读写压力大的时候，也可以增加数据节点。")]),a._v(" "),v("p",[a._v("如果索引设置了多分片，发现在增加了数据节点后，会自动把分片均匀分配到多个节点上了。")]),a._v(" "),v("p",[v("img",{attrs:{src:_(522),alt:"es_readmk_76"}})]),a._v(" "),v("h2",{attrs:{id:"coordinating-node水平扩展"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#coordinating-node水平扩展"}},[a._v("#")]),a._v(" Coordinating node水平扩展")]),a._v(" "),v("p",[a._v("当系统中有大量的复合查询及聚合的时候，可以增加coordinating节点，来增加查询的性能")]),a._v(" "),v("p",[v("img",{attrs:{src:_(523),alt:"es_readmk_77"}})]),a._v(" "),v("h2",{attrs:{id:"ingest节点读写分离"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#ingest节点读写分离"}},[a._v("#")]),a._v(" Ingest节点读写分离")]),a._v(" "),v("p",[a._v("通过定义多个ingest节点，专门用于处理ES的写请求，事先对数据进行ETL的处理。")]),a._v(" "),v("p",[a._v("而平时的读请求，则通过定义多个coordinating node来实现的。")]),a._v(" "),v("p",[v("img",{attrs:{src:_(524),alt:"es_readmk_78"}})]),a._v(" "),v("h2",{attrs:{id:"部署kibana"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#部署kibana"}},[a._v("#")]),a._v(" 部署kibana")]),a._v(" "),v("p",[a._v("我们可以通过把kibana的节点部署在coordinating节点的机器上，因为有些时候直接通过kibana的页面进行日志的查询和统计分析也较为方便。而kibana的访问逻辑和通过coordinating节点的逻辑时同样的。")]),a._v(" "),v("p",[v("img",{attrs:{src:_(525),alt:"es_readmk_79"}})]),a._v(" "),v("h2",{attrs:{id:"hot-warm节点规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hot-warm节点规划"}},[a._v("#")]),a._v(" Hot & Warm节点规划")]),a._v(" "),v("p",[a._v("适用场景：")]),a._v(" "),v("ul",[v("li",[a._v("如果数据通常不会有update操作；")]),a._v(" "),v("li",[a._v("适用于time based索引数据(生命周期管理)，同时数据量比较大的场景。(日志查询场景)")]),a._v(" "),v("li",[a._v("引入warm节点，低配置大容量的机器存放老数据，以降低部署成本。")])]),a._v(" "),v("p",[a._v("不同配置：")]),a._v(" "),v("ul",[v("li",[a._v("Hot节点，通常使用SSD;索引有不断新文档写入。")]),a._v(" "),v("li",[a._v("Warm节点，通常适用HDD；索引不存在新数据的写入；同时也不存在大量的数据查询。")])]),a._v(" "),v("p",[a._v("标记节点：")]),a._v(" "),v("ul",[v("li",[a._v("在ES启动的时候通过node.attr.my_node_type为hot或者warm标签")]),a._v(" "),v("li",[a._v("在写入ES的创建索引的时候，通过setting配置，要求写入host节点。")]),a._v(" "),v("li",[a._v("后期通过index.routing.allocation的一个索引级别的dynamic setting来设置warm。")])]),a._v(" "),v("h1",{attrs:{id:"分片设定和管理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分片设定和管理"}},[a._v("#")]),a._v(" 分片设定和管理")]),a._v(" "),v("h2",{attrs:{id:"为什么要进行索引分片的规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么要进行索引分片的规划"}},[a._v("#")]),a._v(" 为什么要进行索引分片的规划")]),a._v(" "),v("p",[a._v("对于某个索引进行分片的规划和管理是非常重要的工作，是整体ES规划的逻辑部分内容。")]),a._v(" "),v("h2",{attrs:{id:"什么是索引分片的规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么是索引分片的规划"}},[a._v("#")]),a._v(" 什么是索引分片的规划")]),a._v(" "),v("p",[v("strong",[a._v("主要涉及到如何规划一个索引的主分片数和副本分片数")]),a._v("。")]),a._v(" "),v("p",[a._v("ES的分布式特性，主要体现在多分片的设计上。")]),a._v(" "),v("p",[a._v("主分片数量过小，如果该索引增长很快，集群无法通过增加节点实现对这个索引的数据扩展。")]),a._v(" "),v("p",[a._v("主分片数量过大，导致单个分片容量很小，引发一个节点上有过多分片，影响性能。")]),a._v(" "),v("p",[a._v("副本分片数设置过多，会降低集群整体的写入性能。")]),a._v(" "),v("h3",{attrs:{id:"多分片的好处"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#多分片的好处"}},[a._v("#")]),a._v(" 多分片的好处")]),a._v(" "),v("ul",[v("li",[a._v("当分片数 > 节点数的时候，一旦集群中有新的数据节点加入的时候，分片就可以自动进行分配。")]),a._v(" "),v("li",[a._v("分片在重新分配的时候，系统不会有downtime。")]),a._v(" "),v("li",[a._v("一个索引如果分布在不同的节点，多个节点查询可以并行执行。")]),a._v(" "),v("li",[a._v("一个索引如果分布在不同的节点，数据写入可以分散到多个机器。")])]),a._v(" "),v("h3",{attrs:{id:"分片过多的副作用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分片过多的副作用"}},[a._v("#")]),a._v(" 分片过多的副作用")]),a._v(" "),v("ul",[v("li",[a._v("shard分片是ES实现集群水平扩展的最小单位")]),a._v(" "),v("li",[a._v("由于每个分片是一个lucene的索引，分片过多会使用过多的机器的资源。(例如lucene indices/file descriptiors / RAM/ CPU ,每次搜索的请求，需要从每个分片上获取数据，分片的meta信息由master节点维护。控制分片总数在10W以内)")])]),a._v(" "),v("h2",{attrs:{id:"如何做好索引分片的规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何做好索引分片的规划"}},[a._v("#")]),a._v(" 如何做好索引分片的规划")]),a._v(" "),v("h3",{attrs:{id:"注意事项"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#注意事项"}},[a._v("#")]),a._v(" 注意事项")]),a._v(" "),v("ul",[v("li",[a._v("需要注意的是从7.0开始，新创建的一个索引的时候，默认只有一个主分片。")]),a._v(" "),v("li",[a._v("单个分片也有好处，对单个分片的查询算分，聚合不准的问题都可以得到避免。")]),a._v(" "),v("li",[a._v("单个索引，单个分片的时候，集群无法实现水平扩展。")]),a._v(" "),v("li",[a._v("即使增加新的节点，也无法实现水平扩展。")])]),a._v(" "),v("h3",{attrs:{id:"如何确定主分片数"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何确定主分片数"}},[a._v("#")]),a._v(" 如何确定主分片数")]),a._v(" "),v("p",[a._v("从存储的物理角度看：")]),a._v(" "),v("ul",[v("li",[a._v("日志类应用，单个分片不要大于50GB.")]),a._v(" "),v("li",[a._v("搜索类应用，单个分片不要超过20GB.")])]),a._v(" "),v("p",[a._v("为什么要控制主分片存储大小：")]),a._v(" "),v("ul",[v("li",[a._v("提供update的性能")]),a._v(" "),v("li",[a._v("Merge的时候，减少所需的资源")]),a._v(" "),v("li",[a._v("丢失节点后，具备更快的恢复速度 / 便于分片在集群内rebalancing")])]),a._v(" "),v("h3",{attrs:{id:"如何确定副本分片数"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#如何确定副本分片数"}},[a._v("#")]),a._v(" 如何确定副本分片数")]),a._v(" "),v("p",[a._v("副本是主分片的拷贝。")]),a._v(" "),v("p",[a._v("设置合适的副本分片，可以提高系统可用性：相应查询请求，防止数据丢失。")]),a._v(" "),v("p",[a._v("需要占用和主分片一样的资源。")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("副本会降低数据的索引速度：有几份副本就会有几倍的CPU资源消耗在索引上。")])]),a._v(" "),v("li",[v("p",[a._v("会减缓对主分片的查询压力，但是会消耗同样的内存资源")]),a._v(" "),v("p",[a._v("如何机器资源充分，提高副本数，可以提高整体的查询QPS。")])])]),a._v(" "),v("h3",{attrs:{id:"优化节点中分片数量"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化节点中分片数量"}},[a._v("#")]),a._v(" 优化节点中分片数量")]),a._v(" "),v("p",[a._v("如果一个已经运行的集群中里面新增加一台新机器，由于历史数据比较多，ES的自身的均衡机制（分片策略会尽量保证节点上的分片数大致相同）需要很长的时间。而我们的ES集群需要一直对外提供服务的，那么新创建的索引shards基本上都分片到了新机器上了。这样会存在热点数据过于集中，有性能问题。")]),a._v(" "),v("p",[a._v("下面的参数的设置可以解决这些问题，但是需要注意的是，这些设置是强制执行的硬限制，可能会导致某些分片未分片。")]),a._v(" "),v("h4",{attrs:{id:"index-routing-allocation-total-shards-per-node"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#index-routing-allocation-total-shards-per-node"}},[a._v("#")]),a._v(" index.routing.allocation.total_shards_per_node:")]),a._v(" "),v("p",[a._v("动态设置允许你指定每个节点允许的单个索引中分片总数的硬限制.")]),a._v(" "),v("p",[a._v("将分配给单个节点的最大分片数（副本和主分片）。默认为无边界。")]),a._v(" "),v("h4",{attrs:{id:"cluster-routing-allocation-total-shards-per-node"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#cluster-routing-allocation-total-shards-per-node"}},[a._v("#")]),a._v(" cluster.routing.allocation.total_shards_per_node:")]),a._v(" "),v("p",[a._v("可以限制一个节点可以拥有的分片数量，而不考虑索引。")]),a._v(" "),v("p",[a._v("将全局分配给单个节点的最大分片数（副本和主分片）。默认为无边界（"),v("code",[a._v("-1")]),a._v("）。")]),a._v(" "),v("h1",{attrs:{id:"集群容量规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#集群容量规划"}},[a._v("#")]),a._v(" 集群容量规划")]),a._v(" "),v("h2",{attrs:{id:"什么是容量规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么是容量规划"}},[a._v("#")]),a._v(" 什么是容量规划")]),a._v(" "),v("p",[a._v("整理的规划中需要多少个节点，每个索引多少个分片。")]),a._v(" "),v("p",[a._v("这里的规划，更考虑的是磁盘容量的规划。")]),a._v(" "),v("ul",[v("li",[a._v("规划上需要保持一定的余量，当负载出现波动，节点出现丢失时，还能正常工作。")]),a._v(" "),v("li",[a._v("考虑机器的软硬件配置")]),a._v(" "),v("li",[a._v("单条文档的尺寸、文档的总数据量、索引的总数据量(Time base数据保留的时间)、副本分片数")]),a._v(" "),v("li",[a._v("文档是如何写入的(bulk的尺寸)")]),a._v(" "),v("li",[a._v("文档的复杂度，文档是如何进行读取的(怎样进行查询和聚合)")])]),a._v(" "),v("h2",{attrs:{id:"评估业务的性能需求"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#评估业务的性能需求"}},[a._v("#")]),a._v(" 评估业务的性能需求")]),a._v(" "),v("p",[a._v("首先需要评估下业务的性能需求是什么。")]),a._v(" "),v("ul",[v("li",[a._v("数据吞吐及性能需求\n"),v("ul",[v("li",[a._v("数据写入的吞吐量，每秒要求写入多少数据？")]),a._v(" "),v("li",[a._v("查询的吞吐量？")]),a._v(" "),v("li",[a._v("单条查询可以接受的最大返回时间？")])])]),a._v(" "),v("li",[a._v("了解我们的数据\n"),v("ul",[v("li",[a._v("数据的格式和数据的mapping")]),a._v(" "),v("li",[a._v("实际的查询和聚合长的是什么样子")])])])]),a._v(" "),v("h2",{attrs:{id:"两个场景分类"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#两个场景分类"}},[a._v("#")]),a._v(" 两个场景分类")]),a._v(" "),v("p",[a._v("整体ES的使用场景规划，分为两个场景：")]),a._v(" "),v("p",[a._v("搜索类：固定大小的数据集")]),a._v(" "),v("ul",[v("li",[a._v("搜索的数据集增长相对比较缓慢")])]),a._v(" "),v("p",[a._v("日志：基于时间序列的数据")]),a._v(" "),v("ul",[v("li",[a._v("使用ES存放日志与性能指标。数据每天不断写入，增长数据较快")]),a._v(" "),v("li",[a._v("结合warm node做数据的老化处理。")])]),a._v(" "),v("h2",{attrs:{id:"硬件配置的规划"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#硬件配置的规划"}},[a._v("#")]),a._v(" 硬件配置的规划")]),a._v(" "),v("ul",[v("li",[a._v("选择合理的硬件，数据节点尽可能使用SSD")]),a._v(" "),v("li",[a._v("搜索等性能要求高的场景，建议SSD\n"),v("ul",[v("li",[a._v("按照1:10的比例配置内存和硬盘(也有认定为1:16)")])])]),a._v(" "),v("li",[a._v("日志类和查询并发低的场景，可以考虑使用机械硬盘存储\n"),v("ul",[v("li",[a._v("按照1:50的比例配置内存和硬盘(也有认定为1:48到1:96之间)")])])]),a._v(" "),v("li",[a._v("单节点数据建议控制在2TB以内，最大不建议超过5TB")]),a._v(" "),v("li",[a._v("JVM配置机器内存的一半，JVM内存配置不建议超过32G。")])]),a._v(" "),v("h2",{attrs:{id:"容量规划案例1-固定大小的数据集"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#容量规划案例1-固定大小的数据集"}},[a._v("#")]),a._v(" 容量规划案例1：固定大小的数据集")]),a._v(" "),v("p",[a._v("例如存储的一些数据，如唱片信息库，产品信息。")]),a._v(" "),v("p",[a._v("一些特性：")]),a._v(" "),v("ul",[v("li",[a._v("被搜索的数据集很大，但是增长相对比较慢(不会有大量的写入)。更关心搜索和聚合的读取性能。")]),a._v(" "),v("li",[a._v("数据的重要性与时间范围无关。关注的是搜索的相关度。")])]),a._v(" "),v("p",[a._v("估算索引的数据量，然后确定分片的大小：")]),a._v(" "),v("ul",[v("li",[a._v("单个分片的数据不要超过20GB。")]),a._v(" "),v("li",[a._v("可以通过增加副本分片，提高查询的吞吐量。")])]),a._v(" "),v("h2",{attrs:{id:"容量规划案例2-基于时间序列的数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#容量规划案例2-基于时间序列的数据"}},[a._v("#")]),a._v(" 容量规划案例2：基于时间序列的数据")]),a._v(" "),v("ul",[v("li",[v("p",[a._v("相关的用例")]),a._v(" "),v("ul",[v("li",[a._v("日志、指标、安全相关的events")]),a._v(" "),v("li",[a._v("舆情分析")])])]),a._v(" "),v("li",[v("p",[a._v("一些特性")]),a._v(" "),v("ul",[v("li",[a._v("每条数据都有时间戳；文档基本不会被更新(日志和指标数据)")]),a._v(" "),v("li",[a._v("用户更多的会查询近期的数据；对旧的数据查询相对较少")]),a._v(" "),v("li",[a._v("对数据的写入性能要求比较高。")])])])]),a._v(" "),v("h1",{attrs:{id:"索引设计"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引设计"}},[a._v("#")]),a._v(" 索引设计")]),a._v(" "),v("h2",{attrs:{id:"拆分索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#拆分索引"}},[a._v("#")]),a._v(" 拆分索引")]),a._v(" "),v("ul",[v("li",[a._v("如果业务上有大量的查询是基于一个字段进行filter，该字段又是一个数量有限的枚举值。例如订单所在的地区。那么我们可以考虑根据地区来切分索引，这样数据会分散到更多的索引和分片上，有利于提升查询性能。")]),a._v(" "),v("li",[a._v("如果在单个索引上有大量的数据，可以考虑将索引拆分成多个索引。\n"),v("ul",[v("li",[a._v("查询性能可以得到提高")]),a._v(" "),v("li",[a._v("如果要对多个索引进行查询，还可以在查询中指定多个索引得以实现")])])]),a._v(" "),v("li",[a._v("如果业务上有大量的查询是基于一个字段进行filter，该字段数值并不固定的情况下。\n"),v("ul",[v("li",[a._v("可以启用routing功能，按照filter字段的值分布到集群中不同的shard中，降低查询时相关的shard，提高CPU利用率")])])])]),a._v(" "),v("h2",{attrs:{id:"创建基于时间序列的索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#创建基于时间序列的索引"}},[a._v("#")]),a._v(" 创建基于时间序列的索引")]),a._v(" "),v("ul",[v("li",[a._v("创建 time-based索引\n"),v("ul",[v("li",[a._v("在索引的名字中增加时间信息")]),a._v(" "),v("li",[a._v("按照每天、每周、每月的方式进行划分")])])]),a._v(" "),v("li",[a._v("带来的好处\n"),v("ul",[v("li",[a._v("更加合理的组织索引，例如随着时间推移，便于对索引做老化处理\n"),v("ul",[v("li",[a._v("利用hot & warm architecture")]),a._v(" "),v("li",[a._v("备份和删除 （delete by query执行速度慢，底层不会立刻释放空间，而merge时又很消耗资源）")])])])])])]),a._v(" "),v("h2",{attrs:{id:"索引的setting设置"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引的setting设置"}},[a._v("#")]),a._v(" 索引的Setting设置")]),a._v(" "),v("h2",{attrs:{id:"索引的mapping设置"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引的mapping设置"}},[a._v("#")]),a._v(" 索引的mapping设置")]),a._v(" "),v("h1",{attrs:{id:"设计案例1"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#设计案例1"}},[a._v("#")]),a._v(" 设计案例1")]),a._v(" "),v("p",[a._v("现有三台物理机，2路12核，256G，1T的SSD磁盘。")]),a._v(" "),v("p",[a._v("三台机器上分别部署三个master，三个datanode，内存配置31G。")]),a._v(" "),v("p",[a._v("如果是日志类型的应用，单个索引数据是500G。")]),a._v(" "),v("p",[a._v("日志类型的分片单个分片不超过50G，那么就需要10个分片左右。考虑每个索引是10个主分片，另外每个都是1个副本分片。")]),a._v(" "),v("p",[a._v("从使用来看，500G*2分布在三个节点上，每个节点估计使用300多G，估计也只能存储三天的所有数据。要指定相应的索引生命周期策略，定期删除索引。")])])}),[],!1,null,null,null);t.default=e.exports}}]);